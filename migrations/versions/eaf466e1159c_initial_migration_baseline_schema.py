"""Initial migration - baseline schema

Revision ID: eaf466e1159c
Revises: 
Create Date: 2025-05-26 11:37:42.441558

"""
from alembic import op
import sqlalchemy as sa
from sqlalchemy.dialects import postgresql

# revision identifiers, used by Alembic.
revision = 'eaf466e1159c'
down_revision = None
branch_labels = None
depends_on = None


def upgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    op.drop_table('test_test')
    with op.batch_alter_table('app_settings', schema=None) as batch_op:
        batch_op.alter_column('value',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=False)
        batch_op.drop_constraint(batch_op.f('app_settings_key_key'), type_='unique')
        batch_op.drop_index(batch_op.f('idx_app_settings_key'))
        batch_op.create_index(batch_op.f('ix_app_settings_key'), ['key'], unique=True)

    with op.batch_alter_table('billing_info', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('idx_billing_info_is_default'))
        batch_op.drop_index(batch_op.f('idx_billing_info_user_id'))
        batch_op.create_index(batch_op.f('ix_billing_info_user_id'), ['user_id'], unique=False)

    with op.batch_alter_table('cache_entries', schema=None) as batch_op:
        batch_op.alter_column('created_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))
        batch_op.alter_column('updated_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True)
        batch_op.drop_index(batch_op.f('idx_cache_environment'))
        batch_op.drop_index(batch_op.f('idx_cache_type_name'))
        batch_op.drop_column('description')

    with op.batch_alter_table('communication_log', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('idx_communication_log_user_id'))
        batch_op.create_index(batch_op.f('ix_communication_log_user_id'), ['user_id'], unique=False)
        batch_op.drop_constraint(batch_op.f('fk_user_id'), type_='foreignkey')
        batch_op.create_foreign_key(None, 'users', ['user_id'], ['id'])

    with op.batch_alter_table('payment_history', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('idx_payment_history_subscription_id'))
        batch_op.drop_index(batch_op.f('idx_payment_history_user_id'))
        batch_op.create_index(batch_op.f('ix_payment_history_user_id'), ['user_id'], unique=False)

    with op.batch_alter_table('sessions', schema=None) as batch_op:
        batch_op.alter_column('fingerprint',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=True)
        batch_op.drop_index(batch_op.f('idx_sessions_user_id'))
        batch_op.create_index(batch_op.f('ix_sessions_user_id'), ['user_id'], unique=False)

    with op.batch_alter_table('stock_data', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('idx_stock_data_ticker'))
        batch_op.drop_index(batch_op.f('idx_stock_data_timestamp'))
        batch_op.create_index(batch_op.f('ix_stock_data_ticker'), ['ticker'], unique=False)
        batch_op.create_index(batch_op.f('ix_stock_data_timestamp'), ['timestamp'], unique=False)

    with op.batch_alter_table('subscriptions', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('idx_subscriptions_status'))
        batch_op.drop_index(batch_op.f('idx_subscriptions_user_id'))
        batch_op.create_index(batch_op.f('ix_subscriptions_user_id'), ['user_id'], unique=False)

    with op.batch_alter_table('tagged_stocks', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('idx_tagged_stocks_user_id'))
        batch_op.create_index(batch_op.f('ix_tagged_stocks_user_id'), ['user_id'], unique=False)

    with op.batch_alter_table('user_filters', schema=None) as batch_op:
        batch_op.alter_column('filter_data',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=False)
        batch_op.drop_index(batch_op.f('idx_user_filters_user_id'))
        batch_op.create_index(batch_op.f('ix_user_filters_user_id'), ['user_id'], unique=False)

    with op.batch_alter_table('user_history', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('idx_user_history_user_id'))
        batch_op.create_index(batch_op.f('ix_user_history_user_id'), ['user_id'], unique=False)

    with op.batch_alter_table('user_settings', schema=None) as batch_op:
        batch_op.alter_column('value',
               existing_type=postgresql.JSON(astext_type=sa.Text()),
               type_=postgresql.JSONB(astext_type=sa.Text()),
               existing_nullable=False)
        batch_op.drop_index(batch_op.f('idx_user_settings_user_id'))
        batch_op.create_index(batch_op.f('ix_user_settings_user_id'), ['user_id'], unique=False)

    with op.batch_alter_table('users', schema=None) as batch_op:
        batch_op.alter_column('last_login_at',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True)
        batch_op.alter_column('account_locked_until',
               existing_type=postgresql.TIMESTAMP(timezone=True),
               type_=sa.DateTime(),
               existing_nullable=True)
        batch_op.alter_column('lockout_count',
               existing_type=sa.INTEGER(),
               comment=None,
               existing_comment='Number of lockouts due to failed login attempts',
               existing_nullable=False,
               existing_server_default=sa.text('0'))
        batch_op.alter_column('is_disabled',
               existing_type=sa.BOOLEAN(),
               comment=None,
               existing_comment='Indicates if the account is disabled after multiple lockouts',
               existing_nullable=False,
               existing_server_default=sa.text('false'))
        batch_op.alter_column('terms_accepted',
               existing_type=sa.BOOLEAN(),
               nullable=False,
               existing_server_default=sa.text('false'))
        batch_op.drop_index(batch_op.f('idx_users_email'))
        batch_op.drop_index(batch_op.f('idx_users_phone'))
        batch_op.drop_index(batch_op.f('idx_users_username'))
        batch_op.drop_constraint(batch_op.f('users_email_key'), type_='unique')
        batch_op.drop_constraint(batch_op.f('users_phone_key'), type_='unique')
        batch_op.drop_constraint(batch_op.f('users_username_key'), type_='unique')
        batch_op.create_index(batch_op.f('ix_users_email'), ['email'], unique=True)
        batch_op.create_index(batch_op.f('ix_users_phone'), ['phone'], unique=True)
        batch_op.create_index(batch_op.f('ix_users_username'), ['username'], unique=True)

    with op.batch_alter_table('verification_codes', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('idx_verification_codes_type'))
        batch_op.drop_index(batch_op.f('idx_verification_codes_user_id'))
        batch_op.drop_index(batch_op.f('ix_verification_codes_type'))

    # ### end Alembic commands ###


def downgrade():
    # ### commands auto generated by Alembic - please adjust! ###
    with op.batch_alter_table('verification_codes', schema=None) as batch_op:
        batch_op.create_index(batch_op.f('ix_verification_codes_type'), ['verification_type'], unique=False)
        batch_op.create_index(batch_op.f('idx_verification_codes_user_id'), ['user_id'], unique=False)
        batch_op.create_index(batch_op.f('idx_verification_codes_type'), ['verification_type'], unique=False)

    with op.batch_alter_table('users', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_users_username'))
        batch_op.drop_index(batch_op.f('ix_users_phone'))
        batch_op.drop_index(batch_op.f('ix_users_email'))
        batch_op.create_unique_constraint(batch_op.f('users_username_key'), ['username'])
        batch_op.create_unique_constraint(batch_op.f('users_phone_key'), ['phone'])
        batch_op.create_unique_constraint(batch_op.f('users_email_key'), ['email'])
        batch_op.create_index(batch_op.f('idx_users_username'), ['username'], unique=False)
        batch_op.create_index(batch_op.f('idx_users_phone'), ['phone'], unique=False)
        batch_op.create_index(batch_op.f('idx_users_email'), ['email'], unique=False)
        batch_op.alter_column('terms_accepted',
               existing_type=sa.BOOLEAN(),
               nullable=True,
               existing_server_default=sa.text('false'))
        batch_op.alter_column('is_disabled',
               existing_type=sa.BOOLEAN(),
               comment='Indicates if the account is disabled after multiple lockouts',
               existing_nullable=False,
               existing_server_default=sa.text('false'))
        batch_op.alter_column('lockout_count',
               existing_type=sa.INTEGER(),
               comment='Number of lockouts due to failed login attempts',
               existing_nullable=False,
               existing_server_default=sa.text('0'))
        batch_op.alter_column('account_locked_until',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True)
        batch_op.alter_column('last_login_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True)

    with op.batch_alter_table('user_settings', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_user_settings_user_id'))
        batch_op.create_index(batch_op.f('idx_user_settings_user_id'), ['user_id'], unique=False)
        batch_op.alter_column('value',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=postgresql.JSON(astext_type=sa.Text()),
               existing_nullable=False)

    with op.batch_alter_table('user_history', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_user_history_user_id'))
        batch_op.create_index(batch_op.f('idx_user_history_user_id'), ['user_id'], unique=False)

    with op.batch_alter_table('user_filters', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_user_filters_user_id'))
        batch_op.create_index(batch_op.f('idx_user_filters_user_id'), ['user_id'], unique=False)
        batch_op.alter_column('filter_data',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=postgresql.JSON(astext_type=sa.Text()),
               existing_nullable=False)

    with op.batch_alter_table('tagged_stocks', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_tagged_stocks_user_id'))
        batch_op.create_index(batch_op.f('idx_tagged_stocks_user_id'), ['user_id'], unique=False)

    with op.batch_alter_table('subscriptions', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_subscriptions_user_id'))
        batch_op.create_index(batch_op.f('idx_subscriptions_user_id'), ['user_id'], unique=False)
        batch_op.create_index(batch_op.f('idx_subscriptions_status'), ['status'], unique=False)

    with op.batch_alter_table('stock_data', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_stock_data_timestamp'))
        batch_op.drop_index(batch_op.f('ix_stock_data_ticker'))
        batch_op.create_index(batch_op.f('idx_stock_data_timestamp'), ['timestamp'], unique=False)
        batch_op.create_index(batch_op.f('idx_stock_data_ticker'), ['ticker'], unique=False)

    with op.batch_alter_table('sessions', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_sessions_user_id'))
        batch_op.create_index(batch_op.f('idx_sessions_user_id'), ['user_id'], unique=False)
        batch_op.alter_column('fingerprint',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=postgresql.JSON(astext_type=sa.Text()),
               existing_nullable=True)

    with op.batch_alter_table('payment_history', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_payment_history_user_id'))
        batch_op.create_index(batch_op.f('idx_payment_history_user_id'), ['user_id'], unique=False)
        batch_op.create_index(batch_op.f('idx_payment_history_subscription_id'), ['subscription_id'], unique=False)

    with op.batch_alter_table('communication_log', schema=None) as batch_op:
        batch_op.drop_constraint(None, type_='foreignkey')
        batch_op.create_foreign_key(batch_op.f('fk_user_id'), 'users', ['user_id'], ['id'], ondelete='CASCADE')
        batch_op.drop_index(batch_op.f('ix_communication_log_user_id'))
        batch_op.create_index(batch_op.f('idx_communication_log_user_id'), ['user_id'], unique=False)

    with op.batch_alter_table('cache_entries', schema=None) as batch_op:
        batch_op.add_column(sa.Column('description', sa.TEXT(), autoincrement=False, nullable=True))
        batch_op.create_index(batch_op.f('idx_cache_type_name'), ['type', 'name'], unique=False)
        batch_op.create_index(batch_op.f('idx_cache_environment'), ['environment'], unique=False)
        batch_op.alter_column('updated_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True)
        batch_op.alter_column('created_at',
               existing_type=sa.DateTime(),
               type_=postgresql.TIMESTAMP(timezone=True),
               existing_nullable=True,
               existing_server_default=sa.text('CURRENT_TIMESTAMP'))

    with op.batch_alter_table('billing_info', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_billing_info_user_id'))
        batch_op.create_index(batch_op.f('idx_billing_info_user_id'), ['user_id'], unique=False)
        batch_op.create_index(batch_op.f('idx_billing_info_is_default'), ['user_id', 'is_default'], unique=False)

    with op.batch_alter_table('app_settings', schema=None) as batch_op:
        batch_op.drop_index(batch_op.f('ix_app_settings_key'))
        batch_op.create_index(batch_op.f('idx_app_settings_key'), ['key'], unique=False)
        batch_op.create_unique_constraint(batch_op.f('app_settings_key_key'), ['key'])
        batch_op.alter_column('value',
               existing_type=postgresql.JSONB(astext_type=sa.Text()),
               type_=postgresql.JSON(astext_type=sa.Text()),
               existing_nullable=False)

    op.create_table('test_test',
    sa.Column('ident', sa.BIGINT(), autoincrement=False, nullable=True)
    )
    # ### end Alembic commands ###
