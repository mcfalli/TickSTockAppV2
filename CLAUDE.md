# CLAUDE.md - TickStock Development Assistant Guide

## CRITICAL RULES (ALWAYS FOLLOW)

- **ALWAYS** run integration tests before commits and when finalizing a sprint or phase of a sprint: `python run_tests.py`
- **ALWAYS** use specialized agents for development tasks (see Agent Usage below)
- **ALWAYS** use `rg` (ripgrep) instead of `grep` or `find` for searching
- **ALWAYS** use Context7 MCP for current library documentation (Flask, SQLAlchemy, Redis, pandas, etc.)
- **ALWAYS** use WebFetch for Claude Code documentation from https://docs.claude.com/
- **NEVER** mix typed events and dicts after Worker boundary
- **NEVER** reproduce copyrighted content (max 15 words from sources)
- **FIX IT RIGHT** - No band-aids, fix root causes only
- **NEVER** place Generated by Claude comments in code or commits 

## Quick Actions

**Need to implement a feature?**

**PRP Workflow (Recommended)**:
1. `/prp-new-create {feature-name}` - Create implementation-ready PRP
2. `/prp-new-execute {feature-name}.md` - Execute with validation gates
3. Run integration tests: `python run_tests.py`

**Traditional Workflow**:
1. Search project knowledge: What already exists?
2. Check agent triggers: Which agents are needed?
3. Validate approach: Run `architecture-validation-specialist`
4. Implement with tests: Use domain specialists
5. Verify: Run integration tests

**Common Commands**
```bash
# Run tests (MANDATORY before commits)
python run_tests.py
# Expected: 2 tests, ~30 second runtime, pattern flow tests passing

# Alternative test command
python tests/integration/run_integration_tests.py
# Expected: Same as above, more detailed output

# Check project structure
python scripts/dev_tools/generate_structure.py
# Expected: Tree structure of project files

# Database migrations
python model_migrations_run.py migrate "Description"
python model_migrations_run.py upgrade
# Expected: Migration applied, no errors

# Start all services
python start_all_services.py
# Expected: TickStockPL API on :8080, TickStockPL DataLoader, TickStockAppV2 on :5000

# Monitor WebSocket connections
ps aux | grep "flask run"
# Expected: Flask process running with active port
```

## Architecture Essentials

**TickStock.ai** is a high-performance platform for real-time and batch processing of market data, analyzing over 4,000 stock symbols with sub-millisecond efficiency. It leverages a three-tiered architecture—Daily Batch Processing, Intraday Streaming, and Combo Hybrid Intelligence—to detect technical patterns (e.g., Doji, breakouts) and calculate indicators (e.g., RSI, MACD) across intraday, hourly, daily, weekly, and monthly timeframes. Built with Python (pandas, NumPy, SciPy), it integrates Polygon API data and supports modular expansion via a dynamic loading system (NO FALLBACK policy).

**Components:**
- **TickStockAppV2**: Manages UI, authentication, and real-time WebSocket updates; consumes events and triggers jobs via Redis.
- **TickStockPL**: Handles pattern detection, data processing, backtesting, and TimescaleDB management; publishes events to Redis.

**Key Features:**
- Processes thousands of symbols/minute for intraday patterns/indicators
- Performs daily batch analysis for long-term trends, stored in TimescaleDB
- Correlates multi-timeframe signals with fundamentals (e.g., EPS surprises) for <5% false positives
- Achieves >300 symbols/second, >92% cache hit rates, with Flask, SQLAlchemy, and Matplotlib integration

**Redis Pub-Sub**: Ensures loose coupling between components, with channels like tickstock.events.patterns and tickstock:monitoring for real-time events and metrics.



### Code Quality Standards

#### Structure Limits (ENFORCE)
- **Files**: Max 500 lines per file
- **Functions**: Max 50 lines per function
- **Classes**: Max 500 lines per class
- **Line Length**: Max 100 characters
- **Complexity**: Cyclomatic complexity <10

#### Naming Conventions
- **Variables/Functions**: snake_case (e.g., `process_pattern`)
- **Classes**: PascalCase (e.g., `PatternProcessor`)
- **Constants**: UPPER_SNAKE_CASE (e.g., `MAX_RETRIES`)
- **Private**: Prefix with underscore (e.g., `_internal_method`)

#### Development Principles
- **KISS**: Keep It Simple - choose straightforward solutions
- **YAGNI**: You Aren't Gonna Need It - avoid speculative features
- **DRY**: Don't Repeat Yourself - abstract common functionality
- **Fail Fast**: Check errors early, raise exceptions immediately
- **Single Responsibility**: Each component has one clear purpose

### Performance Targets (NON-NEGOTIABLE)

| Operation | Target | Current | Status | Critical Path |
|-----------|--------|---------|--------|---------------|
| Symbol Processing | <1ms | - | 🔄 | Yes |
| WebSocket Delivery | <100ms | 85ms | ✅ | Yes |
| API Response | <50ms | 45ms | ✅ | Yes |
| Database Query | <50ms | - | 🔄 | No |
| Redis Operation | <10ms | - | 🔄 | Yes |

## Agent Usage

### Auto-Trigger Decision Tree
```
START
  ↓
Is it a new task? → YES → architecture-validation-specialist (FIRST)
  ↓ NO
What are you modifying?
  ├── src/processing/* → tickstock-test-specialist + architecture
  ├── src/database/* → database-query-specialist + architecture
  ├── src/redis/* → redis-integration-specialist + integration-testing
  ├── src/api/* → appv2-integration-specialist + database-query
  ├── Security-related → code-security-specialist (MANDATORY)
  └── Documentation → documentation-sync-specialist

ALWAYS END WITH → integration-testing-specialist (MANDATORY)
```

### Quick Agent Reference

| Task Type | Required Agent Workflow |
|-----------|-------------------------|
| New Feature | architecture → domain → test → integration → documentation |
| Bug Fix | domain → test → integration |
| Database Change | database → architecture → test |
| Redis Integration | redis → integration → test |
| UI/API Work | appv2 → database → test |
| Security Updates | security → architecture → test |

## Project Quick Map

### Critical Paths
```
config/          # Application configuration
web/            # Flask templates and static files
src/            # Core application code
tests/          # Test suites
docs/           # Documentation (streamlined)
.claude/agents/ # Specialized AI agents
```

### Key Documentation
- `docs/README.md` - Documentation overview
- `docs/about_tickstock.md` - Platform capabilities
- `docs/architecture/README.md` - System architecture
- `docs/guides/quickstart.md` - Getting started
- `docs/guides/configuration.md` - Configuration reference
- `docs/guides/testing.md` - Testing guide
- `docs/api/endpoints.md` - API documentation
- `docs/PRPs/README.md` - Product Requirement Prompts (PRP) concept
- `docs/PRPs/templates/prp-new.md` - TickStock PRP template

## Sprint Development

### PRP-Enhanced Workflow (RECOMMENDED)

**Product Requirement Prompts (PRPs)** enable one-pass implementation success through context completeness, progressive validation, and pattern consistency.

**Why Use PRPs?**
- ✅ **Context Completeness**: All necessary patterns, gotchas, and references in one document
- ✅ **One-Pass Success**: Pre-loaded context eliminates mid-implementation pivots
- ✅ **Architecture Enforcement**: TickStock-specific constraints (Consumer/Producer roles, Redis patterns)
- ✅ **4-Level Validation**: Progressive gates catch errors early (syntax → unit → integration → architecture)
- ✅ **Knowledge Capture**: PRPs become living documentation of implementation strategies
- ✅ **Reduced Rework**: Dependency-ordered tasks reveal complexity upfront

**When to Use PRPs?**
- ✅ **Complex Features**: Multi-file changes requiring coordination
- ✅ **Cross-System Integration**: Redis pub-sub, WebSocket, or database changes
- ✅ **Architecture-Sensitive**: Changes affecting Producer/Consumer boundaries
- ✅ **Performance-Critical**: Features with specific latency/throughput targets
- ⚠️ **Not for Simple Fixes**: Single-file bug fixes or trivial updates use Traditional Workflow

#### Phase 0: PRP Creation (Use `/prp-new-create {feature-name}`)

**Purpose**: Create implementation-ready PRP with complete context

**Process**:
1. **Deep Research**
   - Search codebase for similar features/patterns
   - Research library documentation (Context7 MCP)
   - Identify existing conventions and test patterns
   - Spawn subagents for parallel research

2. **Context Curation**
   - TickStock architecture context (component roles, Redis channels)
   - Documentation references (specific URLs with anchors)
   - Known gotchas (Worker boundaries, read-only enforcement)
   - Performance targets (specific metrics)

3. **PRP Generation**
   - Use `docs/PRPs/templates/prp-new.md` structure
   - Fill TickStock-specific sections
   - Include dependency-ordered implementation tasks
   - Add 4-level validation gates

4. **Validation**
   - Pass "No Prior Knowledge" test
   - All YAML references specific and accessible
   - Implementation tasks include exact file paths
   - Validation commands project-specific

**Output**: `docs/PRPs/{feature-name}.md`

#### Phase 1: PRP Execution (Use `/prp-new-execute {feature-name}.md`)

**Purpose**: Transform PRP into working code

**Process**:
1. **Load PRP Context**
   - Read PRP completely
   - Absorb architecture constraints
   - Note performance targets
   - Review validation gates

2. **ULTRATHINK & Plan**
   - Create comprehensive implementation plan
   - Break down into TodoWrite tasks
   - Use subagents for parallel work
   - Follow PRP's dependency order

3. **Implementation**
   - Follow PRP's Implementation Tasks sequence
   - Use patterns and examples from PRP
   - Apply TickStock-specific gotchas
   - Write tests alongside code

4. **Progressive Validation** (4 Levels - MANDATORY)
   - **Level 1**: Syntax & style (ruff)
   - **Level 2**: Unit tests (pytest)
   - **Level 3**: Integration tests (`python run_tests.py`)
   - **Level 4**: Architecture/security/performance validation

**Output**: Working code passing all validation gates

### Traditional Workflow (Legacy)

#### Phase 1: Analysis (REQUIRED)
- Understand sprint goal and requirements
- Search project knowledge for existing code
- Run architecture-validation-specialist
- Identify all required agents
- Get explicit approval before coding

#### Phase 2: Implementation (MANDATORY)
- Follow 500 lines/file, 50 lines/function limits
- Use domain specialists for guidance
- Add comprehensive error handling
- Write tests alongside code

#### Phase 3: Validation (MANDATORY)
- Run integration tests: `python run_tests.py`
- Verify performance targets met
- Run code-security-specialist if security-related
- Check for hardcoded credentials
- Ensure no copyright violations

### Phase 4: Sprint Completion (MANDATORY - Both Workflows)
**CRITICAL: Execute POST_SPRINT_CHECKLIST.md**
- Run through entire checklist at `/docs/planning/sprints/POST_SPRINT_CHECKLIST.md`
- Create sprint summary in `/docs/planning/sprints/sprint{N}/SPRINT{N}_COMPLETE.md`
- Update this CLAUDE.md with latest status
- Update BACKLOG.md with deferred items
- ALWAYS ask: **"Is there anything else outstanding?"**
- Remove ALL "Generated by Claude" text
- Commit with proper format (no AI attributions)
- Tag sprint completion in git

## Current Sprint Context
- `docs/planning/sprints/` - Sprint documentation (user-managed)
- `docs/planning/sprints/BACKLOG.md` - Future work items

## 📊 Database & Configuration

### Database Access
```python
# Read-only user for application
User: app_readwrite
# NEVER query pattern tables directly - use Redis cache
# Pattern data comes via Redis pub-sub from TickStockPL
```

### Essential Database Queries
```sql
-- Check active user sessions
SELECT username, last_activity, session_id
FROM user_sessions
WHERE last_activity > NOW() - INTERVAL '1 hour'
ORDER BY last_activity DESC;

-- Monitor WebSocket connections by symbol
SELECT symbol, COUNT(*) as active_connections
FROM ws_subscriptions
GROUP BY symbol
ORDER BY active_connections DESC;

-- Check recent errors from TickStockPL
SELECT severity, message, error_context, created_at
FROM error_logs
WHERE created_at > NOW() - INTERVAL '1 day'
AND severity IN ('error', 'critical')
ORDER BY created_at DESC;

-- View processing run history
SELECT run_id, status, phase, started_at, completed_at,
       EXTRACT(EPOCH FROM (completed_at - started_at)) as duration_seconds
FROM processing_runs
WHERE started_at > NOW() - INTERVAL '7 days'
ORDER BY started_at DESC;

-- Check pattern detection stats
SELECT pattern_name, COUNT(*) as detections, AVG(confidence) as avg_confidence
FROM daily_patterns
WHERE detected_at >= CURRENT_DATE
GROUP BY pattern_name
ORDER BY detections DESC;
```

### Environment Variables (.env)
```bash
# Logging
LOG_FILE_ENABLED=true
LOG_FILE_PATH=logs/tickstock.log
LOG_DB_ENABLED=true
LOG_DB_SEVERITY_THRESHOLD=error

# Redis Channels (with usage examples)
REDIS_ERROR_CHANNEL=tickstock:errors           # System errors
REDIS_PATTERN_CHANNEL=tickstock.events.patterns # Pattern detections

# Subscribe to events (Python example)
# await redis_client.subscribe('tickstock:monitoring')       # Metrics
# await redis_client.subscribe('tickstock:patterns:*')       # All pattern events
# await redis_client.subscribe('tickstock.events.indicators') # Indicators

# Tracing (for debug panel)
TRACE_ENABLED=true
TRACE_TICKERS=["NVDA", "TSLA", "AAPL"]
TRACE_LEVEL=VERBOSE

# TickStockPL Integration
TICKSTOCKPL_API_URL=http://localhost:8080
```

## Common Pitfalls & Solutions
| Pitfall | Solution |
|---------|----------|
| Mixing event types after Worker | Always convert to dict at Worker boundary |
| Database queries in hot path | Use Redis or in-memory cache |
| Skipping tests | Integration tests are MANDATORY |
| Hardcoded credentials | Use environment variables only |
| Large functions | Max 50 lines per function |
| Copyright violations | Max 15 words from sources, with quotes |
| Mock endpoints in production | Remove ALL mock/test endpoints |

## Production Requirements

### Testing Status
```bash
# MANDATORY before any commit
python run_tests.py

# Current test status: 2 tests total
# - Core Integration: May fail if services not running
# - Pattern Flow: Should always pass
# Expected runtime: ~30 seconds
# Known issues: RLock warning (can ignore)
```

### MANDATORY Before Deployment
- ✅ All integration tests passing
- ✅ No mock endpoints or hardcoded data
- ✅ Redis pub-sub connected to TickStockPL
- ✅ Performance targets achieved (<1ms tick, <100ms WebSocket)
- ✅ Security scan completed (no hardcoded passwords)
- ✅ 90%+ test coverage on critical components

### Validation Gates (Track Progress)
- [ ] Integration tests passing (python run_tests.py)
- [ ] WebSocket latency <100ms verified
- [ ] Redis events consuming from TickStockPL
- [ ] No mock/stub endpoints in code
- [ ] Security scan clean (no hardcoded secrets)
- [ ] Memory usage stable under load
- [ ] Error handling tested end-to-end

## Communication Protocol
**When working on tasks:**
1. **Confirm understanding** - Restate the goal
2. **Analyze approach** - Summarize strategy with agent recommendations
3. **Ask clarifications** - Get answers BEFORE coding
4. **Implement** - Use agent workflow throughout
5. **Validate** - Run all required tests
6. **Document** - Update relevant documentation
7. **Document Completion** - Update completion summary

## Current Implementation Status

### Sprint 42 - COMPLETE ✅ (October 12, 2025)
**Architectural Realignment: OHLCV Aggregation**
- ✅ Removed `ohlcv_persistence.py` (433 lines) from TickStockAppV2
- ✅ OHLCV aggregation moved to TickStockPL (TickAggregator)
- ✅ Single source of truth established (0 duplicate bars)
- ✅ Producer/Consumer separation enforced
- ✅ Redis tick forwarding: `tickstock:market:ticks`
- ✅ Integration validated: 220 bars created in 3 minutes
- See: `docs/planning/sprints/sprint42/SPRINT42_COMPLETE.md`

### Sprint 43 - COMPLETE ✅ (October 17, 2025)
**Pattern Display Delay Fix: 5-8 min → 1-2 min**
- ✅ Root cause identified: TickStockPL enforced blanket 5-bar minimum
- ✅ Solution: Pattern-specific bar requirements implemented
- ✅ Diagnostic infrastructure created: `scripts/diagnostics/monitor_redis_channels.py`
- ✅ Enhanced logging in `redis_event_subscriber.py`
- ✅ Live Streaming dashboard updated (raw Redis JSON display)
- ✅ Single-bar patterns detect at bar 1 (1 minute)
- ✅ Multi-bar patterns detect at bar 2 (2 minutes)
- ✅ Redis channels verified working (patterns + indicators flowing)
- See: `docs/planning/sprints/sprint43/SPRINT43_COMPLETE.md`

### System Integration Points (Updated Sprint 42/43)
- **TickStockPL API**: HTTP commands on port 8080
- **Redis Streaming Channels**:
  - `tickstock:patterns:streaming` - Real-time pattern detections ✅
  - `tickstock:patterns:detected` - High confidence (≥80%) ✅
  - `tickstock:indicators:streaming` - Real-time indicators ✅
  - `tickstock:market:ticks` - Raw tick forwarding (AppV2 → PL) ✅
  - `tickstock:streaming:health` - Health metrics ✅
- **Database**: Read-only queries for UI data (enforced)
- **WebSocket**: Real-time browser updates (<100ms delivery)

### Diagnostic Tools (Sprint 43)
```bash
# Monitor Redis channels in real-time
python scripts/diagnostics/monitor_redis_channels.py

# View Live Streaming dashboard
# URL: http://localhost:5000/streaming
# Shows: Raw Redis JSON content for patterns and indicators
```

### Current Performance (Sprint 42/43)
| Metric | Target | Actual | Status |
|--------|--------|--------|--------|
| Pattern Detection Start | <2 min | 1-2 min | ✅ |
| WebSocket Delivery | <100ms | ~50ms | ✅ |
| Redis Operation | <10ms | ~5ms | ✅ |
| Streaming Buffer Flush | 250ms | 250ms | ✅ |
| OHLCV Bar Creation Rate | ~70/min | 70/min | ✅ |

_This document is a living guide. Update it as the project evolves and new patterns emerge._