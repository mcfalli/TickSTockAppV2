# CLAUDE.md - TickStock Development Assistant Guide

## CRITICAL RULES (ALWAYS FOLLOW)

- **ALWAYS** run integration tests before commits and when finalizing a sprint or phase of a sprint: `python run_tests.py`
- **ALWAYS** use specialized agents for development tasks (see Agent Usage below)
- **ALWAYS** use `rg` (ripgrep) instead of `grep` or `find` for searching
- **ALWAYS** use Context7 MCP for current library documentation (Flask, SQLAlchemy, Redis, pandas, etc.)
- **ALWAYS** use WebFetch for Claude Code documentation from https://docs.claude.com/
- **NEVER** mix typed events and dicts after Worker boundary
- **NEVER** reproduce copyrighted content (max 15 words from sources)
- **FIX IT RIGHT** - No band-aids, fix root causes only
- **NEVER** place Generated by Claude comments in code or commits 

## Quick Actions

**Need to implement a feature?**

**PRP Workflow (Recommended)**:
1. `/prp-new-create {feature-name}` - Create implementation-ready PRP
2. `/prp-new-execute {feature-name}.md` - Execute with validation gates
3. Run integration tests: `python run_tests.py`

**Traditional Workflow**:
1. Search project knowledge: What already exists?
2. Check agent triggers: Which agents are needed?
3. Validate approach: Run `architecture-validation-specialist`
4. Implement with tests: Use domain specialists
5. Verify: Run integration tests

**Common Commands**
```bash
# Run tests (MANDATORY before commits)
python run_tests.py
# Expected: 2 tests, ~30 second runtime, pattern flow tests passing

# Alternative test command
python tests/integration/run_integration_tests.py
# Expected: Same as above, more detailed output

# Check project structure
python scripts/dev_tools/generate_structure.py
# Expected: Tree structure of project files

# Database migrations
python model_migrations_run.py migrate "Description"
python model_migrations_run.py upgrade
# Expected: Migration applied, no errors

# Start all services
python start_all_services.py
# Expected: TickStockPL API on :8080, TickStockPL DataLoader, TickStockAppV2 on :5000

# Monitor WebSocket connections
ps aux | grep "flask run"
# Expected: Flask process running with active port

# Sprint 60: Data Maintenance Commands
# Load ETF holdings (incremental update)
python scripts/cache_maintenance/load_etf_holdings.py --mode incremental
# Expected: Skips unchanged ETFs, updates modified ones

# Load universes
python scripts/cache_maintenance/load_universes.py --mode full
# Expected: Loads nasdaq100, sp500, dow30, russell3000

# Enrich sector classifications
python scripts/cache_maintenance/enrich_sectors.py --mode full
# Expected: ~500 stocks classified from sector ETFs

# Generate data quality report
python scripts/cache_maintenance/generate_report.py --summary
# Expected: Summary report with coverage metrics

# Generate detailed markdown report
python scripts/cache_maintenance/generate_report.py --detail --format markdown
# Expected: Comprehensive report with ETF/universe breakdowns
```

## Architecture Essentials

**TickStock.ai** is a high-performance platform for real-time and batch processing of market data, analyzing over 4,000 stock symbols with sub-millisecond efficiency. It leverages a three-tiered architectureâ€”Daily Batch Processing, Intraday Streaming, and Combo Hybrid Intelligenceâ€”to detect technical patterns (e.g., Doji, breakouts) and calculate indicators (e.g., RSI, MACD) across intraday, hourly, daily, weekly, and monthly timeframes. Built with Python (pandas, NumPy, SciPy), it integrates Massive API data and supports modular expansion via a dynamic loading system (NO FALLBACK policy).

**Components:**
- **TickStockAppV2**: Manages UI, authentication, and real-time WebSocket updates; consumes events and triggers jobs via Redis.
- **TickStockPL**: Handles pattern detection, data processing, backtesting, and TimescaleDB management; publishes events to Redis.

**Key Features:**
- Processes thousands of symbols/minute for intraday patterns/indicators
- Performs daily batch analysis for long-term trends, stored in TimescaleDB
- Correlates multi-timeframe signals with fundamentals (e.g., EPS surprises) for <5% false positives
- Achieves >300 symbols/second, >92% cache hit rates, with Flask, SQLAlchemy, and Matplotlib integration
- **Multi-Connection WebSocket Architecture**: Supports up to 3 concurrent WebSocket connections to Massive API for 3x throughput capacity, priority ticker routing, and partial failover capability

**Redis Pub-Sub**: Ensures loose coupling between components, with channels like tickstock.events.patterns and tickstock:monitoring for real-time events and metrics.

**WebSocket Data Ingestion**:
- **Single-Connection Mode** (default): Single WebSocket connection handles all tickers (backward compatible)
- **Multi-Connection Mode** (optional): Up to 3 concurrent connections with independent ticker subscriptions
  - Priority routing: Isolate high-value tickers on dedicated connections
  - Failover: 2/3 connections remain operational if one fails  
  - Throughput: 3x capacity (300+ tickers vs 100 on single connection)
  - Configuration: Universe keys or direct symbol lists per connection
  - Thread-safe callback aggregation for unified data flow



### Code Quality Standards

#### Structure Limits (ENFORCE)
- **Files**: Max 500 lines per file
- **Functions**: Max 50 lines per function
- **Classes**: Max 500 lines per class
- **Line Length**: Max 100 characters
- **Complexity**: Cyclomatic complexity <10

#### Naming Conventions
- **Variables/Functions**: snake_case (e.g., `process_pattern`)
- **Classes**: PascalCase (e.g., `PatternProcessor`)
- **Constants**: UPPER_SNAKE_CASE (e.g., `MAX_RETRIES`)
- **Private**: Prefix with underscore (e.g., `_internal_method`)

#### Development Principles
- **KISS**: Keep It Simple - choose straightforward solutions
- **YAGNI**: You Aren't Gonna Need It - avoid speculative features
- **DRY**: Don't Repeat Yourself - abstract common functionality
- **Fail Fast**: Check errors early, raise exceptions immediately
- **Single Responsibility**: Each component has one clear purpose

### Performance Targets (NON-NEGOTIABLE)

| Operation | Target | Current | Status | Critical Path |
|-----------|--------|---------|--------|---------------|
| Symbol Processing | <1ms | - | ðŸ”„ | Yes |
| WebSocket Delivery | <100ms | 85ms | âœ… | Yes |
| API Response | <50ms | 45ms | âœ… | Yes |
| Database Query | <50ms | - | ðŸ”„ | No |
| Redis Operation | <10ms | - | ðŸ”„ | Yes |

## Agent Usage

### Auto-Trigger Decision Tree
```
START
  â†“
Is it a new task? â†’ YES â†’ architecture-validation-specialist (FIRST)
  â†“ NO
What are you modifying?
  â”œâ”€â”€ src/processing/* â†’ tickstock-test-specialist + architecture
  â”œâ”€â”€ src/database/* â†’ database-query-specialist + architecture
  â”œâ”€â”€ src/redis/* â†’ redis-integration-specialist + integration-testing
  â”œâ”€â”€ src/api/* â†’ appv2-integration-specialist + database-query
  â”œâ”€â”€ Security-related â†’ code-security-specialist (MANDATORY)
  â””â”€â”€ Documentation â†’ documentation-sync-specialist

ALWAYS END WITH â†’ integration-testing-specialist (MANDATORY)
```

### Quick Agent Reference

| Task Type | Required Agent Workflow |
|-----------|-------------------------|
| New Feature | architecture â†’ domain â†’ test â†’ integration â†’ documentation |
| Bug Fix | domain â†’ test â†’ integration |
| Database Change | database â†’ architecture â†’ test |
| Redis Integration | redis â†’ integration â†’ test |
| UI/API Work | appv2 â†’ database â†’ test |
| Security Updates | security â†’ architecture â†’ test |

## Project Quick Map

### Critical Paths
```
config/          # Application configuration
web/            # Flask templates and static files
src/            # Core application code
tests/          # Test suites
docs/           # Documentation (streamlined)
.claude/agents/ # Specialized AI agents
```

### Key Documentation
- `docs/README.md` - Documentation overview
- `docs/about_tickstock.md` - Platform capabilities
- `docs/architecture/README.md` - System architecture
- `docs/guides/quickstart.md` - Getting started
- `docs/guides/configuration.md` - Configuration reference
- `docs/guides/testing.md` - Testing guide
- `docs/api/endpoints.md` - API documentation
- `docs/PRPs/README.md` - Product Requirement Prompts (PRP) concept
- `docs/PRPs/templates/prp-new.md` - TickStock PRP template

## Sprint Development

### PRP-Enhanced Workflow (RECOMMENDED)

**Product Requirement Prompts (PRPs)** enable one-pass implementation success through context completeness, progressive validation, and pattern consistency.

**Why Use PRPs?**
- âœ… **Context Completeness**: All necessary patterns, gotchas, and references in one document
- âœ… **One-Pass Success**: Pre-loaded context eliminates mid-implementation pivots
- âœ… **Architecture Enforcement**: TickStock-specific constraints (Consumer/Producer roles, Redis patterns)
- âœ… **4-Level Validation**: Progressive gates catch errors early (syntax â†’ unit â†’ integration â†’ architecture)
- âœ… **Knowledge Capture**: PRPs become living documentation of implementation strategies
- âœ… **Reduced Rework**: Dependency-ordered tasks reveal complexity upfront

**When to Use PRPs?**
- âœ… **Complex Features**: Multi-file changes requiring coordination
- âœ… **Cross-System Integration**: Redis pub-sub, WebSocket, or database changes
- âœ… **Architecture-Sensitive**: Changes affecting Producer/Consumer boundaries
- âœ… **Performance-Critical**: Features with specific latency/throughput targets
- âš ï¸ **Not for Simple Fixes**: Single-file bug fixes or trivial updates use Traditional Workflow

#### Phase 0: PRP Creation (Use `/prp-new-create {feature-name}`)

**Purpose**: Create implementation-ready PRP with complete context

**Process**:
1. **Deep Research**
   - Search codebase for similar features/patterns
   - Research library documentation (Context7 MCP)
   - Identify existing conventions and test patterns
   - Spawn subagents for parallel research

2. **Context Curation**
   - TickStock architecture context (component roles, Redis channels)
   - Documentation references (specific URLs with anchors)
   - Known gotchas (Worker boundaries, read-only enforcement)
   - Performance targets (specific metrics)

3. **PRP Generation**
   - Use `docs/PRPs/templates/prp-new.md` structure
   - Fill TickStock-specific sections
   - Include dependency-ordered implementation tasks
   - Add 4-level validation gates

4. **Validation**
   - Pass "No Prior Knowledge" test
   - All YAML references specific and accessible
   - Implementation tasks include exact file paths
   - Validation commands project-specific

**Output**: `docs/PRPs/{feature-name}.md`

#### Phase 1: PRP Execution (Use `/prp-new-execute {feature-name}.md`)

**Purpose**: Transform PRP into working code

**Process**:
1. **Load PRP Context**
   - Read PRP completely
   - Absorb architecture constraints
   - Note performance targets
   - Review validation gates

2. **ULTRATHINK & Plan**
   - Create comprehensive implementation plan
   - Break down into TodoWrite tasks
   - Use subagents for parallel work
   - Follow PRP's dependency order

3. **Implementation**
   - Follow PRP's Implementation Tasks sequence
   - Use patterns and examples from PRP
   - Apply TickStock-specific gotchas
   - Write tests alongside code

4. **Progressive Validation** (4 Levels - MANDATORY)
   - **Level 1**: Syntax & style (ruff)
   - **Level 2**: Unit tests (pytest)
   - **Level 3**: Integration tests (`python run_tests.py`)
   - **Level 4**: Architecture/security/performance validation

**Output**: Working code passing all validation gates

### Traditional Workflow (Legacy)

#### Phase 1: Analysis (REQUIRED)
- Understand sprint goal and requirements
- Search project knowledge for existing code
- Run architecture-validation-specialist
- Identify all required agents
- Get explicit approval before coding

#### Phase 2: Implementation (MANDATORY)
- Follow 500 lines/file, 50 lines/function limits
- Use domain specialists for guidance
- Add comprehensive error handling
- Write tests alongside code

#### Phase 3: Validation (MANDATORY)
- Run integration tests: `python run_tests.py`
- Verify performance targets met
- Run code-security-specialist if security-related
- Check for hardcoded credentials
- Ensure no copyright violations

### Phase 4: Sprint Completion (MANDATORY - Both Workflows)
**CRITICAL: Execute POST_SPRINT_CHECKLIST.md**
- Run through entire checklist at `/docs/planning/sprints/POST_SPRINT_CHECKLIST.md`
- Create sprint summary in `/docs/planning/sprints/sprint{N}/SPRINT{N}_COMPLETE.md`
- Update this CLAUDE.md with latest status
- Update BACKLOG.md with deferred items
- ALWAYS ask: **"Is there anything else outstanding?"**
- Remove ALL "Generated by Claude" text
- Commit with proper format (no AI attributions)
- Tag sprint completion in git

## Current Sprint Context
- `docs/planning/sprints/` - Sprint documentation (user-managed)
- `docs/planning/sprints/BACKLOG.md` - Future work items

## ðŸ“Š Database & Configuration

### Database Access
```python
# Read-only user for application
User: app_readwrite
# NEVER query pattern tables directly - use Redis cache
# Pattern data comes via Redis pub-sub from TickStockPL
```

### RelationshipCache Usage (Sprint 60)
```python
# Use cache for all relationship queries (sub-millisecond access)
from src.core.services.relationship_cache import get_relationship_cache

cache = get_relationship_cache()

# Get ETF holdings
holdings = cache.get_etf_holdings('SPY')  # Returns list of symbols

# Get stock's ETFs
etfs = cache.get_stock_etfs('AAPL')  # Returns list of ETF symbols

# Get stock sector
sector = cache.get_stock_sector('AAPL')  # Returns {'sector': '...', 'industry': '...'}

# Get all stocks in a sector
stocks = cache.get_sector_stocks('information_technology')  # Returns list

# Get universe members
members = cache.get_universe_members('nasdaq100')  # Returns list

# Sprint 61: Get universe symbols (WebSocket universe loading)
# Single universe
symbols = cache.get_universe_symbols('nasdaq100')  # Returns 102 symbols
symbols = cache.get_universe_symbols('SPY')  # Returns 504 ETF holdings

# Multi-universe join (distinct union)
symbols = cache.get_universe_symbols('SPY:nasdaq100')  # Returns ~518 distinct symbols
symbols = cache.get_universe_symbols('SPY:QQQ:dow30')  # Returns ~522 distinct symbols

# Cache management endpoints
# GET  /admin/cache/stats    - View cache statistics
# POST /admin/cache/refresh  - Invalidate and refresh
# POST /admin/cache/warm     - Pre-populate cache
```

### Essential Database Queries
```sql
-- Check active user sessions
SELECT username, last_activity, session_id
FROM user_sessions
WHERE last_activity > NOW() - INTERVAL '1 hour'
ORDER BY last_activity DESC;

-- Monitor WebSocket connections by symbol
SELECT symbol, COUNT(*) as active_connections
FROM ws_subscriptions
GROUP BY symbol
ORDER BY active_connections DESC;

-- Check recent errors from TickStockPL
SELECT severity, message, error_context, created_at
FROM error_logs
WHERE created_at > NOW() - INTERVAL '1 day'
AND severity IN ('error', 'critical')
ORDER BY created_at DESC;

-- View processing run history
SELECT run_id, status, phase, started_at, completed_at,
       EXTRACT(EPOCH FROM (completed_at - started_at)) as duration_seconds
FROM processing_runs
WHERE started_at > NOW() - INTERVAL '7 days'
ORDER BY started_at DESC;

-- Check pattern detection stats
SELECT pattern_name, COUNT(*) as detections, AVG(confidence) as avg_confidence
FROM daily_patterns
WHERE detected_at >= CURRENT_DATE
GROUP BY pattern_name
ORDER BY detections DESC;

-- Sprint 59: ETF/Theme/Sector Queries
-- Get ETF holdings
SELECT gm.symbol
FROM definition_groups dg
JOIN group_memberships gm ON dg.id = gm.group_id
WHERE dg.name = 'SPY' AND dg.type = 'ETF' AND dg.environment = 'DEFAULT';

-- Reverse lookup (Stock â†’ ETFs)
SELECT dg.name
FROM definition_groups dg
JOIN group_memberships gm ON dg.id = gm.group_id
WHERE gm.symbol = 'AAPL' AND dg.type = 'ETF' AND dg.environment = 'DEFAULT';

-- Get theme members
SELECT gm.symbol
FROM definition_groups dg
JOIN group_memberships gm ON dg.id = gm.group_id
WHERE dg.name = 'crypto_miners' AND dg.type = 'THEME' AND dg.environment = 'DEFAULT';

-- Count groups by type
SELECT type, COUNT(*) FROM definition_groups
WHERE environment = 'DEFAULT' GROUP BY type;
```

### Environment Variables (.env)
```bash
# Logging
LOG_FILE_ENABLED=true
LOG_FILE_PATH=logs/tickstock.log
LOG_DB_ENABLED=true
LOG_DB_SEVERITY_THRESHOLD=error

# Redis Channels (with usage examples)
REDIS_ERROR_CHANNEL=tickstock:errors           # System errors
REDIS_PATTERN_CHANNEL=tickstock.events.patterns # Pattern detections

# Subscribe to events (Python example)
# await redis_client.subscribe('tickstock:monitoring')       # Metrics
# await redis_client.subscribe('tickstock:patterns:*')       # All pattern events
# await redis_client.subscribe('tickstock.events.indicators') # Indicators

# Tracing (for debug panel)
TRACE_ENABLED=true
TRACE_TICKERS=["NVDA", "TSLA", "AAPL"]
TRACE_LEVEL=VERBOSE

# TickStockPL Integration
TICKSTOCKPL_API_URL=http://localhost:8080

# Multi-Connection WebSocket (optional - default: single connection)
# Enable to utilize up to 3 concurrent WebSocket connections for better throughput
USE_MULTI_CONNECTION=false  # Set to true to enable multi-connection mode
WEBSOCKET_CONNECTIONS_MAX=3  # Maximum concurrent connections (Massive API limit)

# Connection 1: Primary tickers (high-priority symbols)
WEBSOCKET_CONNECTION_1_ENABLED=true
WEBSOCKET_CONNECTION_1_NAME=primary
WEBSOCKET_CONNECTION_1_UNIVERSE_KEY=market_leaders:top_500  # Preferred method
# WEBSOCKET_CONNECTION_1_SYMBOLS=AAPL,NVDA,TSLA,MSFT  # Alternative: direct symbols

# Connection 2: Secondary tickers (optional)
WEBSOCKET_CONNECTION_2_ENABLED=false
WEBSOCKET_CONNECTION_2_UNIVERSE_KEY=finance_sector:large_cap

# Connection 3: Tertiary tickers (optional)
WEBSOCKET_CONNECTION_3_ENABLED=false
```

## Common Pitfalls & Solutions
| Pitfall | Solution |
|---------|----------|
| Mixing event types after Worker | Always convert to dict at Worker boundary |
| Database queries in hot path | Use Redis or in-memory cache |
| Skipping tests | Integration tests are MANDATORY |
| Hardcoded credentials | Use environment variables only |
| Large functions | Max 50 lines per function |
| Copyright violations | Max 15 words from sources, with quotes |
| Mock endpoints in production | Remove ALL mock/test endpoints |

## Production Requirements

### Testing Status
```bash
# MANDATORY before any commit
python run_tests.py

# Current test status: 2 tests total
# - Core Integration: May fail if services not running
# - Pattern Flow: Should always pass
# Expected runtime: ~30 seconds
# Known issues: RLock warning (can ignore)
```

### MANDATORY Before Deployment
- âœ… All integration tests passing
- âœ… No mock endpoints or hardcoded data
- âœ… Redis pub-sub connected to TickStockPL
- âœ… Performance targets achieved (<1ms tick, <100ms WebSocket)
- âœ… Security scan completed (no hardcoded passwords)
- âœ… 90%+ test coverage on critical components

### Validation Gates (Track Progress)
- [ ] Integration tests passing (python run_tests.py)
- [ ] WebSocket latency <100ms verified
- [ ] Redis events consuming from TickStockPL
- [ ] No mock/stub endpoints in code
- [ ] Security scan clean (no hardcoded secrets)
- [ ] Memory usage stable under load
- [ ] Error handling tested end-to-end

## Communication Protocol
**When working on tasks:**
1. **Confirm understanding** - Restate the goal
2. **Analyze approach** - Summarize strategy with agent recommendations
3. **Ask clarifications** - Get answers BEFORE coding
4. **Implement** - Use agent workflow throughout
5. **Validate** - Run all required tests
6. **Document** - Update relevant documentation
7. **Document Completion** - Update completion summary

## Current Implementation Status

### Sprint 42 - COMPLETE âœ… (October 12, 2025)
**Architectural Realignment: OHLCV Aggregation**
- âœ… Removed `ohlcv_persistence.py` (433 lines) from TickStockAppV2
- âœ… OHLCV aggregation moved to TickStockPL (TickAggregator)
- âœ… Single source of truth established (0 duplicate bars)
- âœ… Producer/Consumer separation enforced
- âœ… Redis tick forwarding: `tickstock:market:ticks`
- âœ… Integration validated: 220 bars created in 3 minutes
- See: `docs/planning/sprints/sprint42/SPRINT42_COMPLETE.md`

### Sprint 43 - COMPLETE âœ… (October 17, 2025)
**Pattern Display Delay Fix: 5-8 min â†’ 1-2 min**
- âœ… Root cause identified: TickStockPL enforced blanket 5-bar minimum
- âœ… Solution: Pattern-specific bar requirements implemented
- âœ… Diagnostic infrastructure created: `scripts/diagnostics/monitor_redis_channels.py`
- âœ… Enhanced logging in `redis_event_subscriber.py`
- âœ… Live Streaming dashboard updated (raw Redis JSON display)
- âœ… Single-bar patterns detect at bar 1 (1 minute)
- âœ… Multi-bar patterns detect at bar 2 (2 minutes)
- âœ… Redis channels verified working (patterns + indicators flowing)
- See: `docs/planning/sprints/sprint43/SPRINT43_COMPLETE.md`

### Sprint 55 - COMPLETE âœ… (November 27, 2025)
**ETF Universe Integration & Cache Audit**
- âœ… Added ETF universe dropdown to Historical Data admin page
- âœ… Bulk universe loading: 3-36 symbols with single click
- âœ… Workflow improvement: 5-10 min â†’ <30 sec (90%+ reduction)
- âœ… GET `/admin/historical-data/universes` endpoint (<10ms via CacheControl)
- âœ… POST `/admin/historical-data/trigger-universe-load` endpoint
- âœ… JavaScript handlers with progress polling
- âœ… Cache entries data quality: 100% (254 naming violations fixed, 20 NULL timestamps fixed)
- âœ… Comprehensive documentation: audit report + maintenance procedures
- âœ… Zero regression: Integration tests pass identically to baseline
- âœ… 100% backward compatible: All existing functionality preserved
- See: `docs/planning/sprints/sprint55/SPRINT55_COMPLETE.md`

### Sprint 59 - COMPLETE âœ… (December 21, 2025)
**Relational Database Migration: ETF-Stock Relationships**
- âœ… Migrated from JSONB cache_entries to relational tables
- âœ… Created definition_groups table (ETFs, themes, sectors)
- âœ… Created group_memberships table (many-to-many relationships)
- âœ… Updated all 6 cache_maintenance scripts
- âœ… 10-50x query performance improvement for complex queries
- âœ… Proper referential integrity with foreign keys
- âœ… Zero data loss - all 24 ETFs, 20 themes, 11 sectors migrated
- âœ… 100% bidirectional integrity (11,778 relationships validated)
- See: `docs/planning/sprints/sprint59/SPRINT59_COMPLETE.md`

### Sprint 60 - COMPLETE âœ… (December 21, 2025)
**Production-Ready Data Management & Caching**
- âœ… **Phase 1: Data Loading Procedures**
  - Smart ETF/universe loaders with incremental update mode
  - MD5 checksum-based change detection
  - Pre/post-load validation gates
  - Sector enrichment: 1.38% â†’ 13.41% coverage (+446 stocks)
- âœ… **Phase 2: Runtime Caching Layer**
  - RelationshipCache with <1ms access times
  - 10 query methods, TTL-based expiration
  - Cache management API endpoints
  - Performance: 37ms â†’ 0.01ms (cache hit)
- âœ… **Phase 3: Data Quality Reporting**
  - Report generator with summary/detail views
  - Console, Markdown, JSON output formats
  - Real-time coverage and quality metrics
- âœ… **Phase 4: Documentation**
  - Comprehensive maintenance procedures
  - Load strategy documentation
  - CSV format specifications
- See: `docs/planning/sprints/sprint60/SPRINT60_PLAN.md`

### Sprint 61 - COMPLETE âœ… (December 21, 2025)
**WebSocket Universe Loading via RelationshipCache**
- âœ… **Phase 1: Extend RelationshipCache**
  - Added `get_universe_symbols(universe_key)` method
  - Multi-universe join support: `sp500:nasdaq100` creates distinct union
  - Supports UNIVERSE and ETF types
  - <1ms cache hit performance
- âœ… **Phase 2: Update WebSocket Integration**
  - Migrated multi-connection manager to use RelationshipCache
  - Migrated market data service (single-connection) to RelationshipCache
  - Removed dependency on CacheControl for stock/universe loading
- âœ… **Phase 3: Deprecate CacheControl**
  - Added deprecation warnings to `get_universe_tickers()`
  - Updated class docstring with migration guidance
  - CacheControl now handles non-stock types only
- âœ… **Phase 4: Testing & Validation**
  - 12 integration tests: all passing
  - Cache performance: 56% hit rate during tests
  - Multi-universe joins working: SPY:nasdaq100 = 518 distinct symbols
- âœ… **Phase 5: Documentation**
  - Updated websockets-integration.md with new universe keys
  - Updated CLAUDE.md with Sprint 61 status
  - Added usage examples for multi-universe joins
- See: `docs/planning/sprints/sprint61/SPRINT61_PLAN.md`

### System Integration Points (Updated Sprint 42/43/55/59/60/61)
- **TickStockPL API**: HTTP commands on port 8080
- **Redis Streaming Channels**:
  - `tickstock:patterns:streaming` - Real-time pattern detections âœ…
  - `tickstock:patterns:detected` - High confidence (â‰¥80%) âœ…
  - `tickstock:indicators:streaming` - Real-time indicators âœ…
  - `tickstock:market:ticks` - Raw tick forwarding (AppV2 â†’ PL) âœ…
  - `tickstock:streaming:health` - Health metrics âœ…
  - `tickstock.jobs.data_load` - Historical data load jobs (Sprint 55) âœ…
- **Database**: Read-only queries for UI data (enforced)
- **WebSocket**: Real-time browser updates (<100ms delivery)

### Diagnostic Tools (Sprint 43)
```bash
# Monitor Redis channels in real-time
python scripts/diagnostics/monitor_redis_channels.py

# View Live Streaming dashboard
# URL: http://localhost:5000/streaming
# Shows: Raw Redis JSON content for patterns and indicators
```

### Current Performance (Sprint 42/43)
| Metric | Target | Actual | Status |
|--------|--------|--------|--------|
| Pattern Detection Start | <2 min | 1-2 min | âœ… |
| WebSocket Delivery | <100ms | ~50ms | âœ… |
| Redis Operation | <10ms | ~5ms | âœ… |
| Streaming Buffer Flush | 250ms | 250ms | âœ… |
| OHLCV Bar Creation Rate | ~70/min | 70/min | âœ… |

_This document is a living guide. Update it as the project evolves and new patterns emerge._